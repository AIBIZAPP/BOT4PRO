{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#If you do not have openai and transformer library, remove the \"#\" and run the code below\n",
        "#!pip install openai\n",
        "import numpy as np ;import pandas as pd;\n",
        "import openai\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import clear_output\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_prompt(question,content):\n",
        "    \n",
        "    #You can modify your prompt here.\n",
        "    common_prompt = 'here is your prompt'\n",
        "    \n",
        "    #You can modify your structure of prompt here.\n",
        "    prompt_engineered = f\"{content}\\n\\n{common_prompt}\\n\\n{question}\"\n",
        "\n",
        "    return prompt_engineered\n",
        "\n",
        "\n",
        "def get_response(content,question):\n",
        "\n",
        "    prompt_engineered = build_prompt(question = question, content = content)\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            #{\"role\": \"user\", \"content\": \"\"},\n",
        "            #{\"role\": \"assistant\", \"content\": \"\"},\n",
        "            {\"role\": \"user\", \"content\": prompt_engineered}],\n",
        "        max_tokens=100,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7\n",
        "        )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "excel_name = glob.glob('*.xlsx')\n",
        "\n",
        "for name in excel_name:\n",
        "\n",
        "    excel = pd.read_excel(f'{name}')\n",
        "\n",
        "    for i in range(len(excel)):\n",
        "\n",
        "        print(f\"Working on the {i+1} text in {name}...\")\n",
        "\n",
        "        for u, question in enumerate(excel.columns.tolist()[2:]):\n",
        "\n",
        "            excel.iloc[i,u+2] = get_response(content = excel.iloc[i,0],question = question)\n",
        "\n",
        "        clear_output()\n",
        "\n",
        "    excel.to_excel(f'{name} with info.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
